<!DOCTYPE html><html><body><ul><li>#1 PyTorch Study<ul><li><b>Introduction to PyTorch</b><ol><li>Learn the Basics<ul><li>Learn the Basics<br>Most Machine learning workflows involve working with data, creating models, optimizing model parameters, and saving the trained models.<br><br>머신러닝의 워크플로우:<br>- 데이터로 작업하고<br>- 모델을 만들고<br>- 모델의 패러미터를 최적화 시키고<br>- 학습된 모델을 저장하는 단계로 구성된다. <br><br>본 튜토리얼에서는 파이토치를 이용한 ML Workflow와 그에 대한 개념들을 배우게 될 것이다. 또한 FashionMNIST 데이터셋을 활용하여 입력된 이미지의 태그를 구분하는 classification을 하는 신경망을 학습시킬 것이다.<br></li><li>Running the Tutorial Code<br>제공되는 예시 코드들은 Microsoft Learn을 통한 in the cloud 방식이나, 로컬 머신에서 PyTorch와 TorchVision을 다운받아 사용하는 local 방식이 존재한다. <br></li><li>How to Use this Guide<br>Learn the Basics 대주제의 목차 나열<br></li></ul></li><li>Quickstart<br>본 파트는 머신러닝의 common tasks들을 위한 API들을 간략하게 다룬다. <br><br>- What is API?<br><ul><li>Working with Data<br>파이토치에는 데이터로 작업하기 위한 2가지 primitives가 존재 한다. <br><br>- <a href="https://m.blog.naver.com/aim4u/222108130986">What are primitives?</a><br>주어진 기계의 프로그래머에게 이용가능한 가장 작은 처리의 단위라고 한다. <br><br>```torch.utils.data.DataLoader```<br>```torch.utils.data.Dataset```<br><br>여기서 `Dataset`은 샘플들과 그에 상응하는 라벨들을 저장하며, `DataLoader`는 샘플에 더 쉽게 접근하기 위해 Dataset을 순회 가능한 객체 (iterable)로 감싼다. <br><br>- <a href="https://bluese05.tistory.com/55">What is iterable?</a><br>member를 하나씩 차례로 반환 가능한 object를 말한다고 한다. 예를 들면 sequence type인 list, str, tuple 등이 있는 것이다. <br><br>```import torch<br>from torch import nn<br>from torch.utils.data import DataLoader<br>from torchvision import datasets<br>from torchvision.transforms import ToTensor```<br><br>torch를 임포트하고, nn을 또 임포트, 데이터로더와 데이터셋이랑 ToTensor를 가져온다. <br><br>파이토치는 TorchText, TorchVision, TorchAudio등, 도메인 특화 라이브러리를 데이터셋과 함께 제공해준다. 튜토리얼은 비전을 사용할 예정. 그 중에서도 FashionMNIST 데이터셋을 사용한다. 그 외에도 CIFAR나 COCO같은 다양한 데이터셋 존재함. <br><br>이들 Dataset은 샘플과 정답을 각각 변경하기 위한 transform과 target_transform의 두 인자를 포함한다. <br><br>필요한 라이브러리들 임포트하고, 데이터셋에서 학습 및 테스트 데이터를 내려받은 후, 데이터로더를 생성하는 과정으로 나뉜다. <br><br>```# 공개 데이터셋에서 학습 데이터를 내려받습니다.<br>training_data = datasets.FashionMNIST(<br>    root="data",<br>    train=True,<br>    download=True,<br>    transform=ToTensor(),<br>)<br><br># 공개 데이터셋에서 테스트 데이터를 내려받습니다.<br>test_data = datasets.FashionMNIST(<br>    root="data",<br>    train=False,<br>    download=True,<br>    transform=ToTensor(),<br>)```<br><br>공개 데이터셋 -&gt; 학습 및 테스트 데이터 내려받기<br><br>```batch_size = 64<br><br># 데이터로더를 생성합니다.<br>train_dataloader = DataLoader(training_data, batch_size=batch_size)<br>test_dataloader = DataLoader(test_data, batch_size=batch_size)<br><br>for X, y in test_dataloader:<br>    print(f"Shape of X [N, C, H, W]: {X.shape}")<br>    print(f"Shape of y: {y.shape} {y.dtype}")<br>    break```<br><br>데이터셋을 데이터로더의 인자로 전달하는 과정. <br>그 과정 중에는 iterable로 감싸고, 자동화된 배피, 샘플링, 섞기 및 다중 프로세스로 데이터 불러오기등을 지원한다. 여기서 배치 사이즈를 64로 정의하는데 이는 데이터로더 객체의 각 요소는 64개의 feature 특징과 label 정답을 묶음 batch로 반환한다. <br><br>저 프린트하는게 이해가 안되서 다시 찾아봄<br>데이터셋은 전체 x (input feature)와 y (label)을 tensor로 넣어주면 된다. <br>데이터로더는 배치사이트로 만들어서 학습할 수 있게 형태를 만들어준다. <br><br>```DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None)```<br><br>그니까, 저 프린트문에서는 루프로 데이터 로더의 1,2번째 인자인 데이터셋과 배치사이즈를 불러오는 거고, 데이터셋은 X.shape, Y는 배치사이즈인거지. <br><br>참조: https://didu-story.tistory.com/85<br>데이터로더 안에 들어이쓴 iterable의 element들은 각각 64feature와 label을 저장한 배치를 리턴함.</li><li>Creating Models<br>신경망을 만들려면 nn.Module을 상속받는 클래스를 생성한다. 네트워크의 각 레이어들을 `<i>init</i>` 함수 안에서 선언하며, 데이터가 네트워크를 어떻게 foward propagation 하는지를 `foward`함수에 선언한다. 가능하면 GPU로 한다. <br><br>```# Get cpu or gpu device for training.<br>device = "cuda" if torch.cuda.is_available() else "cpu"<br>print(f"Using {device} device")<br><br># Define model<br>class NeuralNetwork(nn.Module):<br>    def <i>init</i>(self):<br>        super(NeuralNetwork, self).<i>init</i>()<br>        self.flatten = nn.Flatten()<br>        self.linear_relu_stack = nn.Sequential(<br>            nn.Linear(28*28, 512),<br>            nn.ReLU(),<br>            nn.Linear(512, 512),<br>            nn.ReLU(),<br>            nn.Linear(512, 10)<br>        )<br><br>    def forward(self, x):<br>        x = self.flatten(x)<br>        logits = self.linear_relu_stack(x)<br>        return logits<br><br>model = NeuralNetwork().to(device)<br>print(model)```<br><br>cuda가 GPU 사용하는거, 아니면 cpu를 사용한다. <br><br>```super().<i>init</i>()```<br>super()로 기반 클래스(부모 클래스)를 초기화해줌으로써, 기반 클래스의 속성을 subclass가 받아오도록 한다. (초기화를 하지 않으면, 부모 클래스의 속성을 사용할 수 없음)<br><br>cf.) ```super().<i>init</i>()``` vs ```super(MyClass,self).<i>init</i>()```<br><br>좀 더 명확하게 super를 사용하기 위해서는 단순히 super().<i>init</i>()을 하는 것이 아니라 super(파생클래스, self).<i>init</i>() 을 해준다.이와 같이 적어주면 기능적으로 차이는 없지만, 파생클래스와 self를 넣어서 현재 클래스가 어떤 클래스인지 명확하게 표시해줄 수 있다.<br><br>_modules가 초기화 되어 있지 않으면 AttributeError가 발생한다.<br>참조: https://daebaq27.tistory.com/60<br></li><li>Optimizing the Model Parameters<br>모델을 학습시키는데 있어서는 loss function과 optimizer가 필요합니다.<br>loss function이란?<br>정답과 실제 모델의 아웃풋을 비교한 것.<br><br>optimizer란? <br>loss를 최소화 하는 방법.<br><br>```loss_fn = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)```<br><br>한번의 트레이닝 루프안에서 트레이닝 데이터셋에 대한 계산? 예측을 하고, back propagate로 prediction error를 구한뒤 모델 패러미터에 적용한다. <br><br>```def train(dataloader, model, loss_fn, optimizer):<br>    size = len(dataloader.dataset)<br>    model.train()<br>    for batch, (X, y) in enumerate(dataloader):<br>        X, y = X.to(device), y.to(device)<br><br>        # Compute prediction error<br>        pred = model(X)<br>        loss = loss_fn(pred, y)<br><br>        # Backpropagation<br>        optimizer.zero_grad()<br>        loss.backward()<br>        optimizer.step()<br><br>        if batch % 100 == 0:<br>            loss, current = loss.item(), batch * len(X)<br>            print(f"loss: {loss:&gt;7f}  [{current:&gt;5d}/{size:&gt;5d}]")```<br><br>그리고 모델의 성능을 체크한다. <br><br>```def test(dataloader, model, loss_fn):<br>    size = len(dataloader.dataset)<br>    num_batches = len(dataloader)<br>    model.eval()<br>    test_loss, correct = 0, 0<br>    with torch.no_grad():<br>        for X, y in dataloader:<br>            X, y = X.to(device), y.to(device)<br>            pred = model(X)<br>            test_loss += loss_fn(pred, y).item()<br>            correct += (pred.argmax(1) == y).type(torch.float).sum().item()<br>    test_loss /= num_batches<br>    correct /= size<br>    print(f"Test Error: \n Accuracy: {(100*correct):&gt;0.1f}%, Avg loss: {test_loss:&gt;8f} \n")```<br><br>모델의 트레이닝은 epochs 단위만큼 반복된다. epch동안 모델은 패러미터를 학습시키며, 각 epoch마다 accuracy와 loss를 출력하는데, 정확도는 높아지며 로스는 낮아지는 것이 목적이다 .<br><br>```epochs = 5<br>for t in range(epochs):<br>    print(f"Epoch {t+1}\n-------------------------------")<br>    train(train_dataloader, model, loss_fn, optimizer)<br>    test(test_dataloader, model, loss_fn)<br>print("Done!")```<br><br></li><li>Saving Models<br>모델을 저장하는 방법은 모델의 매개변수들을 포함하여 내부 상태 사전을 직렬화 하는 것이다. <br>```torch.save(model.state_dict(), "model.pth")<br>print("Saved PyTorch Model State to model.pth")```</li><li>Loading Models<br>모델을 다시 불러올 때는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함된다. <br><br>```model = NeuralNetwork()<br>model.load_state_dict(torch.load("model.pth"))```<br><br>```classes = [<br>    "T-shirt/top",<br>    "Trouser",<br>    "Pullover",<br>    "Dress",<br>    "Coat",<br>    "Sandal",<br>    "Shirt",<br>    "Sneaker",<br>    "Bag",<br>    "Ankle boot",<br>]<br><br>model.eval()<br>x, y = test_data[0][0], test_data[0][1]<br>with torch.no_grad():<br>    pred = model(x)<br>    predicted, actual = classes[pred[0].argmax(0)], classes[y]<br>    print(f'Predicted: "{predicted}", Actual: "{actual}"')```<br><br></li></ul></li><li>Tensors<br>텐서는 배열이나 행렬과 매우 유사한 자료구조이다. 이를 이용해 모델의 input과 output, parameter들을 encode 부호화한다. 특별히 GPU에서 실행할 수 있으며 넘파이 배열과 동일한 메모리를 공유해서 데이터 복수할 필요도 없고, 자동 미분에 최적화 되어있는다는게 특징이다. <br><br>```import torch<br>import numpy as np```<ul><li>Initializing a Tensor<br>다양한 방법으로 선언을 할 수 있으며 data type도 자동으로 유추해낸다. <br><br>- Directly from data ( torch.tensor() )<br>```data = [[1, 2],[3, 4]]<br>x_data = torch.tensor(data)```<br><br><br>- From a NumPy array ( torch.from_numpy() )<br>```np_array = np.array(data)<br>x_np = torch.from_numpy(np_array)```<br><br><br>- From another tensor ( torch.ones_like )<br>```x_ones = torch.ones_like(x_data) # retains the properties of x_data<br>print(f"Ones Tensor: \n {x_ones} \n")<br><br>x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data<br>print(f"Random Tensor: \n {x_rand} \n")```<br><br><br>- With random or constant values ( torch.rand, ones, zeros )<br>shape는 텐서 차원의 튜플이다. 출력 텐서의 차원을 결정한다. <br>```shape = (2,3,)<br>rand_tensor = torch.rand(shape)<br>ones_tensor = torch.ones(shape)<br>zeros_tensor = torch.zeros(shape)<br><br>print(f"Random Tensor: \n {rand_tensor} \n")<br>print(f"Ones Tensor: \n {ones_tensor} \n")<br>print(f"Zeros Tensor: \n {zeros_tensor}")```<br><br><br><br><br></li><li>Attributes of a Tensor<br>텐서의 속성은 shape과 datatype과 저장된 device정보를 가지고 있다. <br><br>```tensor = torch.rand(3,4)<br><br>print(f"Shape of tensor: {tensor.shape}")<br>print(f"Datatype of tensor: {tensor.dtype}")<br>print(f"Device tensor is stored on: {tensor.device}")```<br><br></li><li>Operations on Tensors<br>100가지가 넘는 arithmetic, 선형대수학, 행렬 manipulation, 샘플링 등이 가능하다. 이는 GPU에서 실행 가능하며 코랩에서는 GPU 세팅을 Runtime &gt; Change runtime type &gt; GPU로 정할 수 있다. 기본으로는 CPU에서 생성된다. `.to`는 GPU로 옮기게 해준다. 시간과 메모리 차원에서 큰 텐서들은 비싸다...<br><br>- Standard numpy-like indexing and slicings<br>```tensor = torch.ones(4, 4)<br>print(f"First row: {tensor[0]}")<br>print(f"First column: {tensor[:, 0]}")<br>print(f"Last column: {tensor[..., -1]}")<br>tensor[:,1] = 0<br>print(tensor)```<br><br><br>- Joining tensors<br>`torch.cat`로 concatenate a sequence of tensors along given dimension 가능. `torch.stack`도 가능함.<br>```t1 = torch.cat([tensor, tensor, tensor], dim=1)<br>print(t1)```<br><br><br>- Arithmetic operations<br>```# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value<br>y1 = tensor @ tensor.T<br>y2 = tensor.matmul(tensor.T)<br><br>y3 = torch.rand_like(y1)<br>torch.matmul(tensor, tensor.T, out=y3)<br><br><br># This computes the element-wise product. z1, z2, z3 will have the same value<br>z1 = tensor * tensor<br>z2 = tensor.mul(tensor)<br><br>z3 = torch.rand_like(tensor)<br>torch.mul(tensor, tensor, out=z3)```<br><br>torch.t(input) : expects input to be &lt;= 2D tensor and transposes dimensions 0 and 1. 2차원 텐서는 transpose(input, 0,1)로 변환된다. 행렬 변환<br><br>y는 행렬 곱셈, z는 일반 곱셈<br><br><br>- Single-element tensors<br>element중 1짜리들은 파이썬의 numerical value로 변환시킬수 있다. item()으로<br>```agg = tensor.sum()<br>agg_item = agg.item()<br>print(agg_item, type(agg_item))```<br><br><br>- In-Place Operations<br>operand의 결과를 저장하는 연산자를 in-place라고 지칭하며 `_`을 사용한다. <br>```print(f"{tensor} \n")<br>tensor.add_(5)<br>print(tensor)```<br><br><br><br><br></li><li>Bridge with NumPy<br>CPU의 텐서들과 넘파이 어레이는 같은 memory location을 공유하며 변화도 공유한다.<br><br>- Tensor to NumPy array<br>```t = torch.ones(5)<br>print(f"t: {t}")<br>n = t.numpy()<br>print(f"n: {n}")<br><br>t.add_(1)<br>print(f"t: {t}")<br>print(f"n: {n}")```<br><br>연산 결과도 공유하는 것을 확인할 수 있다. <br><br><br>- NumPy array to Tensor<br>역으로도 가능하다. <br><br><br><br></li></ul></li></ol></li></ul></li></ul></body></html>