<!DOCTYPE html><html><body><ul><li>#2 PyTorch Study<ul><li><b>Introduction to PyTorch</b><ul><li>4. Datasets &amp; DataLoaders<br>데이터셋을 다루는 코드는 자칫하면 지저분해질 수 있기에, PyTorch의 `torch.utils.data.DataLoader`와 `torch.utils.data.Dataset`을 사용하여 better readability와 modularity를 챙긴다. 기존에 있는 데이터셋이나 나만의 데이터셋을 사용 가능하며 `Dataset`은 샘플과 그에 상응하는 Labels들을 저장하며, `DataLoader`는 `Dataset`을 iterable로 감싸 쉬운 접근이 가능하게 한다. <br><br>이미 존재하는 여러 데이터셋과 그에 대응하는 함수들도 구현되어 있다. <br><br>- Loading a Dataset<br>본 튜토리얼에서는 Fashion-MNIST 데이터셋을 다루는 예시를 보여준다. Fashion-MNIST is a dataset of Zalando’s article images consisting of 60,000 training examples and 10,000 test examples. Each example comprises a 28×28 grayscale image and an associated label from one of 10 classes.<br><br>다음과 같은 parameter들을 가지고 데이터셋을 로드한다. <br><br>	- `root`: train/test data 저장되는 경로<br>	- `train`: specifies training or test dataset<br>	- `download = True`: downloads the data from the internet if it's not available at `root`<br>	- `transform` and `target_transform` specify the feature and label transformations <br><br><br>- Iterating and Visualizing the Dataset<br>우리는 Datasets을 리스트처럼 인덱싱이 가능하다. `training_data[index]`. Matplotlib으로 가능. <br><br>정답들이 들어있는 label map을 리스트 형식으로 생성<br>plt.figure 생성<br>col, rows + 1만큼 반복문, <br>subplot add, 정보 입력, 출력<br><br><br>- Creating a Custom Dataset for your files<br>내가 커스텀 데이터셋을 사용하고 싶으면 3가지 함수를 구현해야 하는데, <br>`<i>init</i>`. `<i>len</i>`, `<i>getitem</i>` 을 구현해야 한다. <br><br>FashionMNIST images는 img_dir 이라는 디렉토리에 저장되어 있는데, 정답 label들은 따로 CSV 파일 `annotation_file`에 저장되어 있다. 이제 각 함수들을 살펴보자. <br><br>- <i>init</i><br>Dataset 오브젝트를 instantiate 할때 한번 실행된다. 이미지와 annotation file과 transform이 포함된 디렉토리를 initialize 해준다. <br><br>- <i>len</i><br>dataset의 샘플 갯수를 리턴해준다. <br><br>- <i>getitem</i><br>주어진 인덱스에서의 샘플을 가져온다. `idx`에 기반하여 디스크의 이미지 위치를 알려주고, `read_image`를 사용해 텐서로 변형후, 그에 상응하는 label을 csv 데이터로부터 `self.img_labels`에서 가져온다. 그리고 transform 함수를 호출하고 텐서 이미지와 상응하는 라벨을 튜플로 리턴해준다. <br><br><br>- Preparing your data for training with DataLoaders<br>`Dataset`은 feature와 label을 한 샘플에 한번 씩 가져온다. 모델을 학습시키는 동안 샘플들을 mini batch로 넘겨주면서 데이터도 섞어주고 epoch 마다, 오버피팅을 줄이기 위해, multiprocessing 을 사용한다. 그럼 데이터 가져오는걸 더 빠르게 할 수 있다. <br><br>DataLoader is iterable that abstracts this complexity for us in API<br><br><br>- Iterate through the DataLoader<br>그렇게 데이터셋을 데이터로더로 로드하면 이제 데이터셋을 iterate할 수 있는데, 각 iteration returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). shuffle = true로 해놔서 배치를 반복할때면 데이터를 섞어준다. <br><br>iter는 반복, 특정 sentinel 나올 때 까지.<br>next는 sentinel 나오면 error 대신 멈추긴 하되 값은 출력함.<br><br></li><li>5. Transforms<br>데이터는 항상 우리가 머신러닝 알고리즘을 학습시키는데 필요한 형태로 들어오지 않는다. 그래서 transforms을 써서 데이터가 학습에 알맞게 수정하는 과정을 거친다. <br><br>TorchVision 데이터셋은 두개의 parameters가 있다.<br>- `transform`: to modify the feature<br>- `target_transform`: to modify the labels - that accept all callables containing the transformation logic.<br><br>토치비전 트랜스폼 모듈에서는 다양한 트랜스폼을 제공한다. <br><br>FashionMNIST features는 PIL 이미지 형식으로 되어 있으며 labels는 integers이다. 학습을 위해서는 features as normalized tensors, labels as one-hot encoded tensors. <br><br>이를 위해 `ToTensor`, `Lambda`를 사용한다. <br><br><br>- ToTensor()<br>PIL 이미지를 넘파이나 ndarray를 FloatTensor로 바꿔주는 역할<br>이미지의 픽셀 intensity calues를 0,1 사이로 scale 해준다.<br><br>- Lambda Transforms<br>유저가 직접 정의할 수 있다. 함수를 정의하는데 integer를 one-hot encoded tensor로 바꿔주는 함수. 처음엔 zero tensor of size 10 (the number of labels in our dataset) 를 생성 후, `scatter_`를 호출하는데 label y의 index에서 value=1로 assign한다.<br><br></li><li>6. Build the Neural Network<br>신경망은 데이터에 operation을 하는 layers modules로 구성된다. torch.nn 네임스페이스는 모든 빌딩 블럭을 제공해준다. <br><br>모든 파이토치 모듈들은 nn.Module의 서브 클래스이다. 신경망은 모듈 그 자체인데 여러개의 또 다른 레이어, 모듈로 구성된 모듈이다. This nested structure allows for building and managing complex archutectures easily.<br><br>- Get Device for Training<br>`torch.cuda`로 GPU를 사용해본다. <br><br>CUDA("Compute Unified Device Architecture", 쿠다)는 <b>그래픽 처리 장치(GPU)에서 수행하는 (병렬 처리) 알고리즘을 C 프로그래밍 언어를 비롯한 산업 표준 언어를 사용하여 작성할 수 있도록 하는 GPGPU 기술</b>이다.<br><br><a href="https://pytorch.org/docs/stable/cuda.html#module-torch.cuda">torch.cuda</a> is used to set up and run CUDA operations. It keeps track of the currently selected GPU, and all CUDA tensors you allocate will by default be created on that device. The selected device can be changed with a <a href="https://pytorch.org/docs/stable/generated/torch.cuda.device.html#torch.cuda.device">torch.cuda.device</a> context manager.<br>However, once a tensor is allocated, you can do operations on it irrespective of the selected device, and the results will be always placed in on the same device as the tensor.<br>Cross-GPU operations are not allowed by default, with the exception of <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.copy_.html#torch.Tensor.copy_">copy_()</a> and other methods with copy-like functionality such as <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.to.html#torch.Tensor.to">to()</a> and <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.cuda.html#torch.Tensor.cuda">cuda()</a>. Unless you enable peer-to-peer memory access, any attempts to launch ops on tensors spread across different devices will raise an error.<br><br>- Define the Class<br>nn.Module의 서브클래싱을 통해 네트워크를 선언한다. <br>네트워크에 필요한 신경망 레이어는 `<i>init</i>`안에서 initialize 해준다. <br>foward method에 input data에서 필요한 operation을 구현하고 있다. <br><br>그리고 나면 `NeuralNetwork().to(device)`로 NeuralNetwork의 Instance를 생성해주고, device로 옮긴다. <br><br>모델을 사용하려면 input data를 넘겨줘야 하는데, 이것은 모델의 foward method를 호출한다. 바로 model.foward() 부르지 말라!<br><br>input과 함께 모델을 호출하면, 10차원의 텐서를 리턴해주는데, 여기에는 각 클래스 별 예측값들이 포함된다. 예측확률은 소프트맥스 모듈의 인스턴스를 통과시켜서 얻는다. <br><br>- Model Layers<br>fashionMNIST 모델의 레이어들을 하나씩 살펴보자. 먼저 입력 샘플 미니배치로 3개의 28x28 사이즈의 리미지를 넣고 네트워크에 돌려본다. <br><br># nn.Flatten<br>각 2D 28x28 이미지를 contiguous 한 784 픽셀 값의 어레이로 바꾸기위해 선언하는 레이어이다. <br>`torch.Size([3, 28, 28])` =&gt; `torch.Size([3, 784])`<br><br># nn.Linear<br>Applies a linear transformation to the incoming data: y = xA^T + by=xAT+b<br>저장된 가중치랑 bias 값을 사용한다. <br><br>레이어1에서 계산, 히든1에서 flat_image 적용<br><br># nn.ReLU<br>Non-Linear activation 함수인데, 이들은 모델의 입출력 간의 complex maping을 생성하는 역할을 한다. 더 다양한 현상을 학습할 수 있도록 비선형적인 요소를 introduce하기 위함이다. <br><br># nn.Sequential<br>ordered container of modules이다. 데이터는 시퀜셜 안에 지정된 모듈 순서 그대로 passed through 된다. quick network를 만드는데 사용할 수 있다. <br><br># nn.Softmax<br>마지막 선형 레이어는 logits을 리턴해준다. <br>logits은 raw values in[-infty, inft]를 뜻하는데, 이 값이 소프트맥스로 전달딘다. <br>logit은 0에서 1사이로 scale되어 있으며, 모델들의 각 클래스별 예측 확률을 represent한다. dim 은 value가 1로 통합되어야 하는 디멘션을 의미한다. <br><br><br>- Model Parameters<br>실제 많은 layers are actually parameterized. nn.Module을 서브클래싱 함으로서 모델 오브젝트 안에있는 모든 필드를 자동적으로 트래킹해주며, 모든 패러미터들을사용가능하게 만들어준다. </li></ul></li></ul></li></ul></body></html>