{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1. Introduction to PyTorch - 7) Automatic Differentiation with torch.autograd.ipynb","provenance":[],"authorship_tag":"ABX9TyMhIJN8Pp2jEKIRhYV/xefE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 단일 계층 신경망 선언"],"metadata":{"id":"aHcHT6ojX1iP"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EN6iM_RXkdu","executionInfo":{"status":"ok","timestamp":1660641828648,"user_tz":-540,"elapsed":3743,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"513e677f-2d0b-4e45-b276-87955ec59358"},"outputs":[{"output_type":"stream","name":"stdout","text":["x =  tensor([1., 1., 1., 1., 1.])\n","y =  tensor([0., 0., 0.])\n","w =  tensor([[-0.7516,  1.0251,  1.2397],\n","        [ 0.4363,  0.0377,  1.1696],\n","        [-0.3732, -1.0043,  1.5362],\n","        [ 0.3138, -0.8930,  1.0109],\n","        [ 0.9929, -0.9790,  0.2220]], requires_grad=True)\n","b =  tensor([-0.6381,  1.1103,  0.0114], requires_grad=True)\n","z =  tensor([-0.0200, -0.7031,  5.1898], grad_fn=<AddBackward0>)\n","loss =  tensor(2.0936, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"]}],"source":["import torch\n","\n","x = torch.ones(5)  # input tensor\n","y = torch.zeros(3)  # expected output\n","w = torch.randn(5, 3, requires_grad=True)\n","b = torch.randn(3, requires_grad=True)\n","z = torch.matmul(x, w)+b\n","loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n","\n","print(\"x = \", x)\n","print(\"y = \", y)\n","print(\"w = \", w)\n","print(\"b = \", b)\n","print(\"z = \", z)\n","print(\"loss = \", loss)"]},{"cell_type":"markdown","source":["## 1. Tensors, Functions and Computational Graph"],"metadata":{"id":"EqdBL52wd8pS"}},{"cell_type":"code","source":["print(f\"Gradient function for z = {z.grad_fn}\")\n","print(f\"Gradient function for loss = {loss.grad_fn}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5y_lDIZteEn0","executionInfo":{"status":"ok","timestamp":1660641830302,"user_tz":-540,"elapsed":5,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"51ea0329-b562-489f-ddec-4e3e21b09bbe"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Gradient function for z = <AddBackward0 object at 0x7f7ec08a6f10>\n","Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f7ec08a6d10>\n"]}]},{"cell_type":"markdown","source":["## 2. Computing Gradients"],"metadata":{"id":"hO4ThRRIeGmc"}},{"cell_type":"code","source":["loss.backward()\n","print(w.grad)\n","print(b.grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pb7fsT41eJUV","executionInfo":{"status":"ok","timestamp":1660641833645,"user_tz":-540,"elapsed":339,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"5949358e-b4e5-4577-bec2-3508f6f958aa"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.1650, 0.1104, 0.3315],\n","        [0.1650, 0.1104, 0.3315],\n","        [0.1650, 0.1104, 0.3315],\n","        [0.1650, 0.1104, 0.3315],\n","        [0.1650, 0.1104, 0.3315]])\n","tensor([0.1650, 0.1104, 0.3315])\n"]}]},{"cell_type":"markdown","source":["## 3. Disabling Gradient Tracking"],"metadata":{"id":"61vS1NxYfw03"}},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","print(z.requires_grad)\n","\n","with torch.no_grad():\n","    z = torch.matmul(x, w)+b\n","print(z.requires_grad)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LS0grQ8f1Gk","executionInfo":{"status":"ok","timestamp":1660641837708,"user_tz":-540,"elapsed":321,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"a197d484-dc20-423f-b48f-a9b9424590df"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"code","source":["z = torch.matmul(x, w)+b\n","z_det = z.detach()\n","print(z_det.requires_grad)"],"metadata":{"id":"qiEBjoa5f7Jr","executionInfo":{"status":"ok","timestamp":1660641843622,"user_tz":-540,"elapsed":321,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"1965d301-c7cb-41ad-edb9-70f031416648","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n"]}]},{"cell_type":"markdown","source":["## 5. "],"metadata":{"id":"9dcQOuAy9xqF"}},{"cell_type":"code","source":["inp = torch.eye(5, requires_grad=True)\n","print(\"inp = \", inp)\n","out = (inp+1).pow(2)\n","print(\"out\", out)\n","out.backward(torch.ones_like(inp), retain_graph=True)\n","print(f\"First call\\n{inp.grad}\")\n","out.backward(torch.ones_like(inp), retain_graph=True)\n","print(f\"\\nSecond call\\n{inp.grad}\")\n","inp.grad.zero_()\n","out.backward(torch.ones_like(inp), retain_graph=True)\n","print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zu4Jwgb9zOw","executionInfo":{"status":"ok","timestamp":1660642112349,"user_tz":-540,"elapsed":328,"user":{"displayName":"박경륜","userId":"10938890239157918829"}},"outputId":"45698e33-7208-41a3-838d-3bf0d4ebee6b"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["inp =  tensor([[1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.]], requires_grad=True)\n","out tensor([[4., 1., 1., 1., 1.],\n","        [1., 4., 1., 1., 1.],\n","        [1., 1., 4., 1., 1.],\n","        [1., 1., 1., 4., 1.],\n","        [1., 1., 1., 1., 4.]], grad_fn=<PowBackward0>)\n","First call\n","tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.],\n","        [2., 2., 2., 2., 4.]])\n","\n","Second call\n","tensor([[8., 4., 4., 4., 4.],\n","        [4., 8., 4., 4., 4.],\n","        [4., 4., 8., 4., 4.],\n","        [4., 4., 4., 8., 4.],\n","        [4., 4., 4., 4., 8.]])\n","\n","Call after zeroing gradients\n","tensor([[4., 2., 2., 2., 2.],\n","        [2., 4., 2., 2., 2.],\n","        [2., 2., 4., 2., 2.],\n","        [2., 2., 2., 4., 2.],\n","        [2., 2., 2., 2., 4.]])\n"]}]}]}